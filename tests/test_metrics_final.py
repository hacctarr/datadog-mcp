#!/usr/bin/env python3
"""
Final test script for metrics with real data
"""

import asyncio
import os

async def test_metrics_final():
    """Test metrics with real data"""
    print("Testing Service Metrics with Real Data...")
    
    try:
        from utils.datadog_client import fetch_metrics
        from utils.formatters import format_metrics_table, format_metrics_summary
        
        # Test single metric with data
        print("ğŸ” Testing single metric with data...")
        result = await fetch_metrics(
            metric_name="datadog.estimated_usage.logs.ingested_bytes",
            time_range="1d",
            filters={"service": "content"}
        )
        
        print(f"âœ… Status: {result.get('status')}")
        if result.get('series'):
            series = result['series'][0]
            points = series.get('pointlist', [])
            print(f"âœ… Points: {len(points)}")
            
            if points:
                # Show last few values
                recent_points = points[-3:]
                print("Recent values:")
                for timestamp, value in recent_points:
                    if value is not None:
                        import datetime
                        # Datadog timestamps are in milliseconds
                        dt = datetime.datetime.fromtimestamp(timestamp / 1000)
                        print(f"  {dt.strftime('%H:%M')}: {value:.0f}")
        
        # Test multiple metrics
        print(f"\nğŸ” Testing multiple metrics...")
        metrics_to_test = [
            "datadog.estimated_usage.logs.ingested_bytes",
            "datadog.estimated_usage.logs.indexed_logs"
        ]
        
        multiple_results = {}
        for metric_name in metrics_to_test:
            try:
                result = await fetch_metrics(
                    metric_name=metric_name,
                    time_range="4h",
                    filters={"service": "content"}
                )
                multiple_results[metric_name] = result
            except Exception as e:
                multiple_results[metric_name] = {"error": str(e)}
        
        print(f"âœ… Retrieved {len(multiple_results)} metrics")
        
        # Test table formatting with real data
        print(f"\nğŸ” Testing table formatting...")
        table = format_metrics_table(multiple_results)
        print("Metrics Table:")
        print(table)
        
        # Test summary formatting
        print(f"\nğŸ” Testing summary formatting...")
        summary = format_metrics_summary(multiple_results)
        print("Metrics Summary:")
        print(summary[:500] + "..." if len(summary) > 500 else summary)
        
        # Test different time ranges
        print(f"\nğŸ” Testing different time ranges...")
        time_ranges = ["1h", "4h", "1d"]
        
        for time_range in time_ranges:
            result = await fetch_metrics(
                metric_name="datadog.estimated_usage.logs.ingested_bytes",
                time_range=time_range,
                filters={"service": "content"}
            )
            
            if result.get('series'):
                points = result['series'][0].get('pointlist', [])
                print(f"   {time_range}: {len(points)} points")
            else:
                print(f"   {time_range}: No data")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return
    
    print("\nğŸ‰ Metrics with real data work perfectly!")

if __name__ == "__main__":
    asyncio.run(test_metrics_final())